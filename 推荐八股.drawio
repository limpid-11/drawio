<mxfile host="app.diagrams.net" agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36 Edg/127.0.0.0" version="24.7.7">
  <diagram name="第 1 页" id="iWVoZDMzAQuaJpYY_TNt">
    <mxGraphModel dx="1729" dy="833" grid="1" gridSize="10" guides="1" tooltips="1" connect="1" arrows="1" fold="1" page="0" pageScale="1" pageWidth="827" pageHeight="1169" math="0" shadow="0">
      <root>
        <mxCell id="0" />
        <mxCell id="1" parent="0" />
        <mxCell id="mPcpz4siuyIrg-kaVJwC-1" value="协同过滤&lt;div&gt;1）基于用户的&lt;/div&gt;&lt;div&gt;2）基于物品的&lt;/div&gt;&lt;div&gt;实现方法&lt;/div&gt;&lt;div&gt;利用用户item的共现矩阵学习用户和item的表示&lt;/div&gt;&lt;div&gt;内积可以表示成相似度&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;持久化操作&lt;/div&gt;&lt;div&gt;cache()函数与persist()函数&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;正则化调整输入数据的分布，使网络收敛更稳定&lt;/div&gt;&lt;div&gt;BN指对特征进行归一化&lt;/div&gt;&lt;div&gt;LN指对样本进行归一化&lt;/div&gt;&lt;div&gt;图像中多用BN，NLP中多用LN&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;AUC指标&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;特征的筛选&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Node2vec&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Cross&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;优化器&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;为什么交叉熵损失函数？&lt;/div&gt;" style="rounded=0;whiteSpace=wrap;html=1;align=left;verticalAlign=top;spacingLeft=4;" parent="1" vertex="1">
          <mxGeometry x="-30" y="-20" width="510" height="420" as="geometry" />
        </mxCell>
        <mxCell id="Wk424I4RCr_Jomv0QLjG-1" value="&lt;div&gt;信息熵的概念：那些接近确定性的分布（输出几乎可以确定）具有较低的熵，那些接近均匀分布的概率分布具有较高的熵。&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;为啥交叉熵用于分类任务？&lt;/div&gt;&lt;div&gt;https://zhuanlan.zhihu.com/p/35709485&lt;br&gt;&lt;/div&gt;&lt;div&gt;（1）与分类正确率相比，无法细分模型的准确度。&lt;/div&gt;&lt;div&gt;（2）与 MSE相比，由于分类模型的输出通常是sigmod或者softmax，所以反向传播计算得到的梯度，如果是交叉熵的话，等于(c(x)-y)*xi，能做到误差越小，梯度越小，误差越大，梯度越大。相较于MSE，收敛速度更快，收敛更稳定。&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;优化器&lt;/div&gt;&lt;div&gt;https://zhuanlan.zhihu.com/p/261695487&lt;br&gt;&lt;/div&gt;&lt;div&gt;作用是通过对下降方向和下降步长定义，是一种梯度下降的策略的体现。&lt;/div&gt;&lt;div&gt;（1）SCD 随机梯度下降，每次只利用一个样本进行提取下降&lt;/div&gt;&lt;div&gt;（2）SCD 带动量，不仅由当前的方向决定，还由之前的决定（一阶动量是指数移动平均值）&lt;/div&gt;&lt;div&gt;（3）NAG 利于跳出局部最优，但是收敛速度慢&lt;/div&gt;&lt;div&gt;（4）AdaGrad 使用二阶动量使得学习率衰减&lt;/div&gt;&lt;div&gt;（5）AdaDelta 使用窗口的指数移动平均数计算二阶动量&lt;/div&gt;&lt;div&gt;（6）Adam 一阶动量调整下降方向+二阶动量使学习率衰减 减小了鞍点附近的震荡&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;" style="rounded=0;whiteSpace=wrap;html=1;align=left;verticalAlign=top;spacingLeft=4;" vertex="1" parent="1">
          <mxGeometry x="-560" y="-20" width="510" height="420" as="geometry" />
        </mxCell>
      </root>
    </mxGraphModel>
  </diagram>
</mxfile>
